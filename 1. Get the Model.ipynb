{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a5f046d-461b-4c74-95c0-de57fd51c50c",
   "metadata": {},
   "source": [
    "# Check packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e603c4e3-c960-4175-ae72-2d704c00198a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVINO version: 2024.0.0-14509-34caeefd078-releases/2024/0\n"
     ]
    }
   ],
   "source": [
    "import openvino as ov\n",
    "\n",
    "print(f\"OpenVINO version: {ov.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c368dad3-508c-4198-aab2-4596ce7690eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openvino-dev version: 2024.0.0\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "package_name = \"openvino-dev\"\n",
    "\n",
    "try:\n",
    "    distribution = pkg_resources.get_distribution(package_name)\n",
    "    version = distribution.version\n",
    "    print(f\"{package_name} version: {version}\")\n",
    "except pkg_resources.DistributionNotFound:\n",
    "    print(f\"{package_name} is not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee93a8-173d-466a-8b15-4b4dec365c33",
   "metadata": {},
   "source": [
    "# Open Model Zoo (OMZ) Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa1f4d3-0c85-4bc4-a1b0-1f5d6477558a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: omz_downloader [-h] [--name PAT[,PAT...]] [--list FILE.LST] [--all]\n",
      "                      [--print_all] [--precisions PREC[,PREC...]] [-o DIR]\n",
      "                      [--cache_dir DIR] [--num_attempts N]\n",
      "                      [--progress_format {text,json}] [-j N]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --name PAT[,PAT...]   download only models whose names match at least one of\n",
      "                        the specified patterns\n",
      "  --list FILE.LST       download only models whose names match at least one of\n",
      "                        the patterns in the specified file\n",
      "  --all                 download all available models\n",
      "  --print_all           print all available models\n",
      "  --precisions PREC[,PREC...]\n",
      "                        download only models with the specified precisions\n",
      "                        (actual for DLDT networks); specify one or more of:\n",
      "                        FP32-INT8,FP32-INT1,FP16-INT1,FP16,FP32,FP16-INT8\n",
      "  -o DIR, --output_dir DIR\n",
      "                        path where to save models\n",
      "  --cache_dir DIR       directory to use as a cache for downloaded files\n",
      "  --num_attempts N      attempt each download up to N times\n",
      "  --progress_format {text,json}\n",
      "                        which format to use for progress reporting\n",
      "  -j N, --jobs N        how many downloads to perform concurrently\n"
     ]
    }
   ],
   "source": [
    "! omz_downloader -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2adce0ce-dafc-499d-9ea3-726b26529fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclnet\n",
      "aclnet-int8\n",
      "action-recognition-0001\n",
      "age-gender-recognition-retail-0013\n",
      "anti-spoof-mn3\n",
      "asl-recognition-0004\n",
      "background-matting-mobilenetv2\n",
      "bert-base-ner\n",
      "bert-large-uncased-whole-word-masking-squad-0001\n",
      "bert-large-uncased-whole-word-masking-squad-emb-0001\n",
      "bert-large-uncased-whole-word-masking-squad-int8-0001\n",
      "bert-small-uncased-whole-word-masking-squad-0001\n",
      "bert-small-uncased-whole-word-masking-squad-0002\n",
      "bert-small-uncased-whole-word-masking-squad-emb-int8-0001\n",
      "bert-small-uncased-whole-word-masking-squad-int8-0002\n",
      "brain-tumor-segmentation-0002\n",
      "cocosnet\n",
      "colorization-siggraph\n",
      "colorization-v2\n",
      "common-sign-language-0001\n",
      "common-sign-language-0002\n",
      "convnext-tiny\n",
      "ctdet_coco_dlav0_512\n",
      "ctpn\n",
      "deeplabv3\n",
      "densenet-121-tf\n",
      "detr-resnet50\n",
      "dla-34\n",
      "driver-action-recognition-adas-0002\n",
      "drn-d-38\n",
      "efficientdet-d0-tf\n",
      "efficientdet-d1-tf\n",
      "efficientnet-b0\n",
      "efficientnet-b0-pytorch\n",
      "efficientnet-v2-b0\n",
      "efficientnet-v2-s\n",
      "emotions-recognition-retail-0003\n",
      "erfnet\n",
      "f3net\n",
      "face-detection-0200\n",
      "face-detection-0202\n",
      "face-detection-0204\n",
      "face-detection-0205\n",
      "face-detection-0206\n",
      "face-detection-adas-0001\n",
      "face-detection-retail-0004\n",
      "face-detection-retail-0005\n",
      "face-recognition-resnet100-arcface-onnx\n",
      "face-reidentification-retail-0095\n",
      "faceboxes-pytorch\n",
      "facenet-20180408-102900\n",
      "facial-landmarks-35-adas-0002\n",
      "facial-landmarks-98-detection-0001\n",
      "fast-neural-style-mosaic-onnx\n",
      "faster-rcnn-resnet101-coco-sparse-60-0001\n",
      "faster_rcnn_inception_resnet_v2_atrous_coco\n",
      "faster_rcnn_resnet50_coco\n",
      "fastseg-large\n",
      "fastseg-small\n",
      "fbcnn\n",
      "fcrn-dp-nyu-depth-v2-tf\n",
      "formula-recognition-medium-scan-0001\n",
      "formula-recognition-polynomials-handwritten-0001\n",
      "forward-tacotron\n",
      "gaze-estimation-adas-0002\n",
      "gmcnn-places2-tf\n",
      "googlenet-v1-tf\n",
      "googlenet-v2-tf\n",
      "googlenet-v3\n",
      "googlenet-v3-pytorch\n",
      "googlenet-v4-tf\n",
      "gpt-2\n",
      "handwritten-english-recognition-0001\n",
      "handwritten-japanese-recognition-0001\n",
      "handwritten-score-recognition-0003\n",
      "handwritten-simplified-chinese-recognition-0001\n",
      "hbonet-0.25\n",
      "hbonet-1.0\n",
      "head-pose-estimation-adas-0001\n",
      "higher-hrnet-w32-human-pose-estimation\n",
      "horizontal-text-detection-0001\n",
      "hrnet-v2-c1-segmentation\n",
      "human-pose-estimation-0001\n",
      "human-pose-estimation-0005\n",
      "human-pose-estimation-0006\n",
      "human-pose-estimation-0007\n",
      "human-pose-estimation-3d-0001\n",
      "hybrid-cs-model-mri\n",
      "i3d-rgb-tf\n",
      "icnet-camvid-ava-0001\n",
      "icnet-camvid-ava-sparse-30-0001\n",
      "icnet-camvid-ava-sparse-60-0001\n",
      "image-retrieval-0001\n",
      "inception-resnet-v2-tf\n",
      "instance-segmentation-person-0007\n",
      "instance-segmentation-security-0002\n",
      "instance-segmentation-security-0091\n",
      "instance-segmentation-security-0228\n",
      "instance-segmentation-security-1039\n",
      "instance-segmentation-security-1040\n",
      "landmarks-regression-retail-0009\n",
      "levit-128s\n",
      "license-plate-recognition-barrier-0001\n",
      "license-plate-recognition-barrier-0007\n",
      "machine-translation-nar-de-en-0002\n",
      "machine-translation-nar-en-de-0002\n",
      "machine-translation-nar-en-ru-0002\n",
      "machine-translation-nar-ru-en-0002\n",
      "mask_rcnn_inception_resnet_v2_atrous_coco\n",
      "mask_rcnn_resnet50_atrous_coco\n",
      "midasnet\n",
      "mixnet-l\n",
      "mobilenet-v1-0.25-128\n",
      "mobilenet-v1-1.0-224-tf\n",
      "mobilenet-v2-1.0-224\n",
      "mobilenet-v2-1.4-224\n",
      "mobilenet-v2-pytorch\n",
      "mobilenet-v3-large-1.0-224-tf\n",
      "mobilenet-v3-small-1.0-224-tf\n",
      "mobilenet-yolo-v4-syg\n",
      "modnet-photographic-portrait-matting\n",
      "modnet-webcam-portrait-matting\n",
      "mozilla-deepspeech-0.6.1\n",
      "mozilla-deepspeech-0.8.2\n",
      "nanodet-m-1.5x-416\n",
      "nanodet-plus-m-1.5x-416\n",
      "netvlad-tf\n",
      "nfnet-f0\n",
      "noise-suppression-denseunet-ll-0001\n",
      "noise-suppression-poconetlike-0001\n",
      "open-closed-eye-0001\n",
      "pedestrian-and-vehicle-detector-adas-0001\n",
      "pedestrian-detection-adas-0002\n",
      "person-attributes-recognition-crossroad-0230\n",
      "person-attributes-recognition-crossroad-0234\n",
      "person-attributes-recognition-crossroad-0238\n",
      "person-detection-0106\n",
      "person-detection-0200\n",
      "person-detection-0201\n",
      "person-detection-0202\n",
      "person-detection-0203\n",
      "person-detection-0301\n",
      "person-detection-0302\n",
      "person-detection-0303\n",
      "person-detection-action-recognition-0005\n",
      "person-detection-action-recognition-0006\n",
      "person-detection-action-recognition-teacher-0002\n",
      "person-detection-asl-0001\n",
      "person-detection-raisinghand-recognition-0001\n",
      "person-detection-retail-0002\n",
      "person-detection-retail-0013\n",
      "person-reidentification-retail-0277\n",
      "person-reidentification-retail-0286\n",
      "person-reidentification-retail-0287\n",
      "person-reidentification-retail-0288\n",
      "person-vehicle-bike-detection-2000\n",
      "person-vehicle-bike-detection-2001\n",
      "person-vehicle-bike-detection-2002\n",
      "person-vehicle-bike-detection-2003\n",
      "person-vehicle-bike-detection-2004\n",
      "person-vehicle-bike-detection-crossroad-0078\n",
      "person-vehicle-bike-detection-crossroad-1016\n",
      "person-vehicle-bike-detection-crossroad-yolov3-1020\n",
      "product-detection-0001\n",
      "pspnet-pytorch\n",
      "quartznet-15x5-en\n",
      "regnetx-3.2gf\n",
      "repvgg-a0\n",
      "repvgg-b1\n",
      "repvgg-b3\n",
      "resnest-50-pytorch\n",
      "resnet-18-pytorch\n",
      "resnet-34-pytorch\n",
      "resnet-50-pytorch\n",
      "resnet-50-tf\n",
      "resnet18-xnor-binary-onnx-0001\n",
      "resnet50-binary-0001\n",
      "retinaface-resnet50-pytorch\n",
      "retinanet-tf\n",
      "rexnet-v1-x1.0\n",
      "rfcn-resnet101-coco-tf\n",
      "road-segmentation-adas-0001\n",
      "robust-video-matting-mobilenetv3\n",
      "semantic-segmentation-adas-0001\n",
      "shufflenet-v2-x1.0\n",
      "single-human-pose-estimation-0001\n",
      "single-image-super-resolution-1032\n",
      "single-image-super-resolution-1033\n",
      "smartlab-action-recognition-0001\n",
      "smartlab-object-detection-0001\n",
      "smartlab-object-detection-0002\n",
      "smartlab-object-detection-0003\n",
      "smartlab-object-detection-0004\n",
      "smartlab-sequence-modelling-0001\n",
      "smartlab-sequence-modelling-0002\n",
      "ssd-resnet34-1200-onnx\n",
      "ssd_mobilenet_v1_coco\n",
      "ssd_mobilenet_v1_fpn_coco\n",
      "ssdlite_mobilenet_v2\n",
      "swin-tiny-patch4-window7-224\n",
      "t2t-vit-14\n",
      "text-detection-0003\n",
      "text-detection-0004\n",
      "text-image-super-resolution-0001\n",
      "text-recognition-0012\n",
      "text-recognition-0014\n",
      "text-recognition-0015\n",
      "text-recognition-0016\n",
      "text-recognition-resnet-fc\n",
      "text-spotting-0005\n",
      "text-to-speech-en-0001\n",
      "text-to-speech-en-multi-0001\n",
      "time-series-forecasting-electricity-0001\n",
      "ultra-lightweight-face-detection-rfb-320\n",
      "ultra-lightweight-face-detection-slim-320\n",
      "unet-camvid-onnx-0001\n",
      "vehicle-attributes-recognition-barrier-0039\n",
      "vehicle-attributes-recognition-barrier-0042\n",
      "vehicle-detection-0200\n",
      "vehicle-detection-0201\n",
      "vehicle-detection-0202\n",
      "vehicle-detection-adas-0002\n",
      "vehicle-license-plate-detection-barrier-0106\n",
      "vehicle-license-plate-detection-barrier-0123\n",
      "vehicle-reid-0001\n",
      "vitstr-small-patch16-224\n",
      "wav2vec2-base\n",
      "wavernn\n",
      "weld-porosity-detection-0001\n",
      "yolact-resnet50-fpn-pytorch\n",
      "yolo-v1-tiny-tf\n",
      "yolo-v2-ava-0001\n",
      "yolo-v2-ava-sparse-35-0001\n",
      "yolo-v2-ava-sparse-70-0001\n",
      "yolo-v2-tf\n",
      "yolo-v2-tiny-ava-0001\n",
      "yolo-v2-tiny-ava-sparse-30-0001\n",
      "yolo-v2-tiny-ava-sparse-60-0001\n",
      "yolo-v2-tiny-tf\n",
      "yolo-v2-tiny-vehicle-detection-0001\n",
      "yolo-v3-onnx\n",
      "yolo-v3-tf\n",
      "yolo-v3-tiny-onnx\n",
      "yolo-v3-tiny-tf\n",
      "yolo-v4-tf\n",
      "yolo-v4-tiny-tf\n",
      "yolof\n",
      "yolox-tiny\n"
     ]
    }
   ],
   "source": [
    "! omz_downloader --print_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2634fb62-15c7-4e54-9c23-a554753f7ac0",
   "metadata": {},
   "source": [
    "# Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c21aa0-d323-4638-8ddd-542af9cd89f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! omz_downloader --name face-detection-adas-0001 --precision FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b79ec-548a-4a30-b607-2ed3352abfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "! omz_downloader --name emotions-recognition-retail-0003 --precision FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb2812c-5a7f-4a9b-bfee-fae76b182f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading age-gender-recognition-retail-0013 ||################\n",
      "\n",
      "========== Downloading C:\\BrainAI\\openvino101\\intel\\age-gender-recognition-retail-0013\\FP16\\age-gender-recognition-retail-0013.xml\n",
      "... 100%, 42 KB, 44 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading C:\\BrainAI\\openvino101\\intel\\age-gender-recognition-retail-0013\\FP16\\age-gender-recognition-retail-0013.bin\n",
      "... 24%, 1024 KB, 697 KB/s, 1 seconds passed\n",
      "... 49%, 2048 KB, 1213 KB/s, 1 seconds passed\n",
      "... 73%, 3072 KB, 1709 KB/s, 1 seconds passed\n",
      "... 98%, 4096 KB, 2096 KB/s, 1 seconds passed\n",
      "... 100%, 4175 KB, 2137 KB/s, 1 seconds passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! omz_downloader --name age-gender-recognition-retail-0013 --precision FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23824a6c-334d-47d5-afc4-4762e1d9696a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
